联合学习（FL）是一种机器学习设置，其中许多客户机（例如移动设备或整个组织）在中央服务器（例如服务提供商）的协调下协同训练模型，同时保持培训数据的分散。FL体现了集中数据收集和最小化的原则，能够减轻传统的集中机器学习和数据科学方法所带来的许多系统隐私风险和成本。本文以外语研究的爆炸性增长为动力，讨论了近年来的研究进展，并提出了一系列开放性问题和挑战。
1 介绍
联合学习（FL）是一种机器学习环境，在这种环境下，许多客户机（如移动设备或整个组织）在中央服务器（如服务提供商）的协调下协作训练模型，同时保持训练数据的分散性。它体现了集中收集和数据最小化的原则，可以减轻传统的、集中的机器学习带来的许多系统隐私风险和成本。从研究和应用的角度来看，这一领域最近受到了极大的关注。本文描述了联合学习设置的定义特点和挑战，强调了重要的实际约束和考虑因素，然后列举了一系列有价值的研究方向。这项工作的目标是突出具有重大理论和实际意义的研究问题，并鼓励对可能对现实世界产生重大影响的问题进行研究。
McMahan等人于2016年引入了联邦学习一词。[289]：“我们称我们的方法为联合学习，因为学习任务由一个由中央服务器协调的参与设备（我们称为客户端）松散联合解决。”一种不平衡的、非IID（同一且独立分布）的数据分区，跨越大量不可靠的设备由于通信带宽有限，引入了一系列挑战。
重要的相关工作早在联合学习这个术语被引入之前。许多研究团体（包括密码学、数据库和机器学习）追求的长期目标是分析和学习分布在许多所有者之间的数据，而不暴露这些数据。用于计算加密数据的加密方法是从20世纪80年代早期开始发展起来的[340421]，Agrawal和Srikant[15]和Vaidya等人。[390]是早期工作的例子，这些工作试图从使用集中服务器的本地数据中学习，同时保护隐私。相反，即使自从引入了联合学习这一术语，我们也意识到没有任何一项工作可以直接解决外语学习的全部挑战。因此，联邦学习这一术语提供了一个方便的速记，用来描述一组特征、约束和挑战，这些特征、约束和挑战常常在分散数据的应用ML问题中同时出现，其中隐私是最重要的。
本文来源于2019年6月17日至18日在谷歌西雅图办公室举办的联合学习与分析研讨会。在为期两天的活动中，很明显需要一份广泛的论文来调查联合学习领域的许多开放性挑战
所讨论的许多问题的一个关键特性是它们本质上是跨学科的——解决这些问题可能不仅需要机器学习，还需要来自分布式优化、密码学、安全、差异隐私、公平性、压缩感知、系统、信息论、统计学等技术。许多最困难的问题都出现在这些领域的交叉点上，因此我们相信，合作对于不断取得进展至关重要。这项工作的目标之一是强调这些领域的技术可以潜在地结合起来的方式，既带来了有趣的可能性，也带来了新的挑战。
自从联合学习一词最初是以移动和边缘设备应用为重点引入的[289287]，人们对将FL应用于其他应用的兴趣大大增加，包括一些可能只涉及少数相对可靠客户的应用程序，例如多个组织合作培训模型。我们将这两种联合学习设置分别称为“cross device”和“cross silo”。考虑到这些变化，我们提出了一个更宽泛的联合学习定义：集中更新是指范围狭窄的更新，以包含手头特定学习任务所需的最少信息；在数据最小化的服务中尽可能早地进行聚合。我们注意到，这一定义将联合学习与完全分散（对等）学习技术区分开来，如第2.1节所述。
虽然隐私保护数据分析的研究已经有50多年的历史，但只有在过去的十年中，解决方案才得到大规模的应用（例如[156135]）。跨设备联合学习和联合数据分析现在正被应用于消费类数字产品中。Google在Gboard移动键盘[323196420,98,329]以及像素手机[18]和Android消息[375]中广泛使用了联合学习。虽然谷歌率先推出了跨设备FL，但现在人们对这种设置的兴趣更为广泛，例如：苹果在iOS 13[27]中使用了跨设备FL，用于QuickType键盘和“Hey Siri”的人声分类[28]；ai博士正在为医学研究开发跨设备FL解决方案[130]，Snips已经探索了跨设备FL用于热词检测[259]。
交叉筒仓应用也被提出或描述在许多领域，包括再保险的财务风险预测[407]、药品发现[158]、电子健康记录挖掘[162]、医疗数据分割[19121]和智能制造[305]。
对联合学习技术的日益增长的需求导致了许多工具和框架的出现。其中包括TensorFlow Federated[38]、Federated AI Technology Enabler[34]、PySyft[342]、Leaf[35]、Padlefl[36]和Clara Training Framework[33]；更多详细信息见附录A。包含联合学习的商业数据平台正在由成熟的技术公司和小型初创企业开发。
表1对比了跨设备和跨思洛存储器的联合学习与跨一系列轴的传统单数据中心分布式学习。这些特性建立了许多实际的联邦学习系统通常必须满足的约束条件，因此既有助于激励联邦学习中的开放性挑战，也为其提供了信息。接下来的章节将详细讨论这些问题。
这两种FL变体被称为具有代表性和重要的示例，但不同的FL设置可能具有这些特性的不同组合。在本文的其余部分，我们考虑交叉设备的FL设置，除非另有说明，尽管许多问题也适用于其他FL设置。第2节专门讨论了许多其他变体和应用。
接下来，我们将更详细地考虑跨设备联合学习，重点放在典型的大规模技术部署中常见的实际方面；Bonawitz等人。[74]提供了特定生产系统的更多细节，包括对特定架构选择和考虑的讨论。
本节采用应用视角，与上一节不同，本节不试图进行定义。相反，目标是描述跨设备FL中的一些实际问题，以及它们如何融入到更广泛的机器学习开发和部署生态系统中。希望为接下来的开放性问题提供有用的背景和动机，并帮助研究人员估计在实际系统中部署特定的新方法有多直接。在考虑FL培训流程之前，我们首先绘制模型的生命周期。
图1:FL训练模型的生命周期和联邦学习系统中的各种参与者。第4节从威胁模型的角度重新审视了该图。
1.1.1联合学习中模型的生命周期
FL过程通常由模型工程师为特定应用开发模型。例如，自然语言处理领域的专家可以开发一个用于虚拟键盘的下一个单词预测模型。图1显示了主要组件和参与者。在高水平上，典型的工作流程是：
1问题识别：模型工程师识别出一个需要用FL解决的问题。
2客户端检测：如果需要，客户端（例如在移动电话上运行的应用程序）被指示在本地存储必要的培训数据（有时间和数量限制）。在许多情况下，应用程序已经存储了这些数据（例如，文本消息应用程序必须存储文本消息，照片管理应用程序已经存储了照片）。然而，在某些情况下，可能需要维护额外的数据或元数据，例如用户交互数据，以便为监督的学习任务提供标签。
3仿真原型（可选）：模型工程师可以在FL仿真中使用代理数据集原型化模型体系结构和测试学习超参数。
4联邦模型训练：启动多个联邦训练任务来训练模型的不同变体，或者使用不同的优化超参数。
5（联合）模型评估：在任务经过充分培训后（通常是几天，见下文），对模型进行分析并选择合适的候选对象。分析可以包括在数据中心的标准数据集上计算的指标，或者是联合评估，其中模型被推送到外部客户机，以便对本地客户机数据进行评估。
6部署：最后，一旦选择了一个好的模型，它就要经过一个标准的模型发布过程，包括手动质量保证、实时a/B测试（通常在某些设备上使用新模型，在其他设备上使用上一代模型来比较它们的体内性能），以及分阶段推出（以便不良行为可以在影响太多用户之前发现并回滚）。模型的特定启动过程由应用程序的所有者设置，通常与模型的培训方式无关。换句话说，这一步同样适用于使用联合学习或传统数据中心方法训练的模型。
FL系统面临的主要实际挑战之一是使上述工作流程尽可能直接，理想地接近ML系统实现的集中培训的易用性。虽然本文的大部分内容都是专门针对联邦培训的，但是还有许多其他组件，包括联邦分析任务，如模型评估和调试。改进这些是第3.4节的重点。现在，我们更详细地考虑单个FL模型的训练（上面的第4步）。
1.1.2典型的联合培训过程
我们现在考虑一个包含McMa-han等人的联邦平均算法的FL训练模板。[289]还有许多其他的例子；同样，变化也是可能的，但这给出了一个共同的起点。
服务器（服务提供商）通过重复以下步骤来协调培训过程，直到培训停止（由监控培训过程的模型工程师自行决定）：
1客户机选择：服务器从一组满足资格要求的客户机中取样。例如，为了避免影响设备的用户，移动电话可能只会在插入、未测量的wi-fi连接和空闲的情况下登录到服务器。
2广播：选定的客户机从服务器下载当前模型权重和培训程序（例如TensorFlow图[6]）。
三。客户机计算：每个选定的设备通过执行训练程序在本地计算对模型的更新，例如可以在本地数据上运行SGD（在联邦平均中）。
4聚合：服务器收集设备更新的聚合。为了提高效率，一旦有足够数量的设备报告结果，可能会在此时丢弃掉队者。这一阶段也是许多其他技术的集成点，稍后将讨论这些技术，可能包括：安全聚合以增加隐私，对聚合进行有损压缩以提高通信效率，以及添加噪声和更新剪辑以实现差异隐私。
5模型更新：服务器根据从参与当前回合的客户端计算的聚合更新本地更新共享模型。
表2给出了移动设备上典型的联邦学习应用程序所涉及数量的典型数量级大小。
客户机计算、聚合和模型更新阶段的分离并不是联邦学习的严格要求，它确实排除了某些算法类，例如异步SGD，其中每个客户机的更新立即应用于模型，然后再与其他客户机的更新进行任何聚合。这种异步方法可以简化系统设计的某些方面，而且从优化的角度来看也是有益的（尽管这一点可以争论）。然而，上述方法在提供不同研究领域之间的关注点分离方面具有实质性优势：压缩、差分隐私和安全多方计算方面的进展可以针对标准原语（如在分散更新上计算和或平均数）开发，然后组合对于任意优化或分析算法，只要这些算法是用聚合原语表示的。
值得强调的是，在两个方面，外语培训过程不应影响用户体验。首先，如上所述，尽管模型参数通常在每轮联合训练的广播阶段发送到一些设备，但这些模型是训练过程中短暂的一部分，不用于向用户显示“实时”预测。这一点很重要，因为训练ML模型很有挑战性，对超参数的错误配置会产生一个做出错误预测的模型。相反，用户对模型的可见使用将推迟到模型生命周期的第6步中详述的推出过程。第二，培训本身对用户来说是不可见的-如客户选择中所述，培训不会减慢设备速度或耗尽电池电量，因为它只在设备空闲并连接电源时执行。然而，这些限制带来的有限可用性直接导致开放性研究挑战，这些挑战将在随后讨论，例如半周期数据可用性和客户选择中的潜在偏差。
1.2联合学习研究
本文的其余部分调查了许多由现实世界联合学习环境的约束和挑战所激发的开放性问题，从医院系统的医疗数据培训模型到使用数亿移动设备的培训。不用说，大多数研究联合学习问题的研究人员很可能不会部署生产FL系统，也无法访问数以百万计的真实世界设备。这导致了激励工作的实际设置与模拟实验之间的关键区别，模拟实验提供了激励问题给定方法的适用性证据。
从实验角度来看，这使得外语研究与其他领域有所不同，这导致在进行外语研究时需要额外考虑。特别是，在突出显示开放性问题时，我们还试图在可能的情况下，指出可在模拟中测量的相关性能指标、使其更能代表真实世界性能的数据集的特征等。模拟的需要也会对演示产生影响FL研究。虽然我们并不打算是权威的或绝对的，但我们对FL研究提出了以下温和的建议，以解决我们所描述的开放性问题：
如表1所示，FL设置可包含广泛的问题。与设定和目标已确立的领域相比，准确描述特定的FL设置的详细信息非常重要，尤其是当提议的方法做出的假设可能并不适用于所有设置时（例如参与所有回合的状态良好的客户）。
当然，任何模拟的细节都应该呈现出来，以使研究具有可重复性。但是，为了有效地证明在模拟问题上取得成功意味着在现实世界目标上取得了有益的进展，解释模拟设置的哪些方面（而不是哪个方面）也很重要。我们希望本文中的指导将对此有所帮助。
在FL中，隐私和通信效率始终是首要考虑的问题，即使实验是使用公共数据在一台机器上运行的模拟。与其他类型的ML相比，对于任何建议的方法来说，重要的是要清楚地知道计算发生在哪里以及传递什么
联邦学习模拟软件库以及标准数据集有助于缓解开展有效外语研究的挑战；附录A总结了当前可用的一些选项。为不同的联合学习环境（跨设备和跨思洛存储器）开发标准评估指标和建立标准基准数据集仍然是当前工作的重要方向。
1.3组织
第2节建立在表1的思想基础上，探讨了其他FL设置和问题，超出了最初对跨设备设置的关注。第3节接着转向关于提高联合学习效率和有效性的核心问题。第4节仔细考虑了威胁模型，并考虑了一系列旨在实现严格隐私保护的技术。与所有的机器学习系统一样，在联合学习应用程序中，可能存在操纵正在训练的模型的动机，各种各样的失败是不可避免的；这些挑战将在第5节中讨论。最后，我们将在第6节讨论提供公平和无偏见模型的重要挑战。
2放松核心FL假设：应用于新兴环境和场景
在本节中，我们将讨论与上一节讨论的主题相关的研究领域。尽管不是本文其余部分的主要重点，但这些领域的进展可以激励下一代生产系统的设计。
2.1完全分散/点对点分布式学习
在联合学习中，中央服务器协调培训过程并接收所有客户端的贡献。因此，服务器是一个中心参与者，它也可能代表单点故障。虽然大型公司或组织可以在某些应用程序场景中扮演这一角色，但在更具协作性的学习场景中，并不总是可以使用或需要可靠和强大的中央服务器[392]。此外，当客户机数量非常大时，服务器甚至可能成为瓶颈，如Lian等人所示。[266]（尽管这可以通过仔细的系统设计来减轻，例如[74]）。
完全分散学习的关键思想是用单个客户机之间的点对点通信取代与服务器的通信。通信拓扑被表示为一个连通图，其中节点是客户端，边表示两个客户端之间的通信信道。网络图通常被选择为稀疏且最大度较小，因此每个节点只需要向少量对等方发送/接收消息；这与服务器-客户端体系结构的星形图相反。在完全分散算法中，一轮对应于每个客户端执行本地更新并与图中的邻居交换信息。在机器学习的背景下，局部更新是一个典型的局部（随机）梯度步，通信过程是将一个人的局部模型参数平均化。需要注意的是，模型不再像标准的联邦学习那样是全局状态，但是过程可以被设计成所有局部模型收敛到期望的全局解，即单个模型逐渐达成一致。虽然多智能体优化在控制界有着悠久的历史，但最近在机器学习中考虑了SGD和其他优化算法的完全分散变体，以提高数据中心的可扩展性[30]以及分散设备网络[110，392，379，54，243，253，153]。他们考虑的是无向网络图，尽管有向网络（编码在现实世界中可能出现的单向信道，如社交网络或数据市场）的情况也在[30200]中进行了研究。
值得注意的是，即使在上述分散的环境中，中央当局仍可能负责制定学习任务。例如，考虑以下问题：谁决定在分散环境中培训什么样的模型？使用什么算法？什么超参数？当某些东西不能按预期工作时，谁负责调试？要回答这些问题，仍然需要参与的客户对中央当局有一定程度的信任。或者，可以由提出学习任务的客户做出决定，或者通过协商一致的方案进行合作（见第2.1.2节）。
表3提供了联合学习和点对点学习之间的比较。虽然分散式学习的架构假设与联合学习的架构假设不同，但它通常可以应用于类似的问题领域，许多相同的挑战也会出现，而且在研究社区中存在明显的重叠。因此，在本文中，我们也考虑了分散学习；在本节中，我们提出了挑战
表3：联合学习和完全分散学习之间的主要区别的比较。注意，与FL一样，分散式学习可以进一步划分为不同的用例，其区别与表1中比较交叉筒仓和交叉设备FL的用例相似。
明确考虑了分散方法的具体情况，但在分散的情况下，其他部分中的许多开放问题也会出现。
2.1.1算法挑战
在机器学习的去中心化方案的真实可用性这一主题上，有大量重要的算法问题尚未解决。有些问题类似于使用中央服务器进行联合学习的特殊情况，而其他挑战则是完全分散或缺乏信任的附加副作用。我们在下面概述一些特定领域。
网络拓扑和异步性对分散SGD的影响完全分散的学习算法应该对有限的客户端可用性（客户端暂时不可用，在执行过程中退出或加入）和有限的网络可靠性（可能有消息丢失）。而对于广义线性模型的特殊情况，使用对偶结构的方案可以实现某些期望的鲁棒性[201]，对于深度学习和SGD的情况，这仍然是一个有待解决的问题。当网络图是完整的，但消息有固定的概率被丢弃时，Yu等人。[427]表明一个人可以达到与可靠网络相当的收敛速度。其他开放性研究问题涉及非IID数据分布、更新频率、有效通信模式和实际收敛时间[379]，如下所述。
良好连接或更密集的网络鼓励更快的一致性，并提供更好的误差收敛速度（这取决于网络图的频谱间隙），但它们会导致通信延迟，而延迟会随着节点度数的增加而增加。大多数优化理论都没有明确考虑拓扑结构如何影响运行时，即完成每个SGD迭代所需的时钟时间。Wang等人。[401]提出了一种基于匹配分解采样的分散SGD方法MATCHA，该方法在保持相同的误差收敛速度的同时，减少了任何给定节点拓扑的每次迭代的通信延迟。其核心思想是将图拓扑分解为由可并行运行的不相交通信链路组成的匹配，并在每次迭代中仔细选择这些匹配的子集。这个子图序列导致在连接关键链路上的通信更频繁（确保快速的错误收敛），而在其他链路上的通信则更少（节省通信延迟）。
分散SGD的设置自然也有助于异步算法，其中每个客户端在随机时间独立地独立地活动，消除了全局同步的需要，并可能提高可扩展性[110、392、54、30、267]。
局部更新分散式SGD在通信轮之前执行多个局部更新步骤的方案的理论分析比使用单个SGD步骤的方案更具挑战性，例如在小批量SGD中。虽然这也将在后面的第3.2节中讨论，但在完全分散的利益环境中，这一点也更为普遍。依赖于单个本地更新步骤的方案通常被证明在非IID本地数据集的情况下收敛[243242]。最近，Wang和Joshi[399]对具有几个局部更新步骤的情况进行了收敛性分析。此外，[401]为非IID数据情况提供了收敛性分析，但针对基于上述匹配分解采样的特定方案。然而，一般来说，如何理解非IID数据分布下的收敛性，以及如何设计一个模型平均策略以达到最快的收敛速度仍然是一个有待解决的问题。
个性化和信任机制类似于跨设备FL设置，在可供个人客户端使用的非IID数据分布下，完全分散场景的一个重要任务是设计用于学习个性化模型集合的算法。[392，54]的工作引入了完全分散的算法，通过平滑具有相似任务（即相似的数据分布）的客户机之间的模型参数，协作学习每个客户机的个性化模型。Zantedeschi等人。[431]结合个性化模型进一步学习相似度图。在分散环境中，关键的独特挑战之一仍然是这种方案对恶意行为者或不可靠数据或标签的贡献的鲁棒性。将激励或机制设计与分散学习相结合是一个新兴的重要目标，在没有可信的中央服务器的情况下，这一目标可能更难实现。
梯度压缩和量化方法在潜在的应用中，客户通常在可用的通信带宽和允许的能量使用方面受到限制。将现有的一些压缩通信方案从集中式协调器辅助的环境转换为完全分散的，而不影响融合是一个积极的研究方向[243335380242]。一个补充的想法是设计分散优化算法，这自然会产生稀疏更新[431]。
2.1.2实际挑战
完全分散学习的一个正交问题是如何实际实现。本节概述了一系列基于分布式账本思想的相关思想。
区块链是在不同用户之间共享的分布式账本，使得数字交易成为可能，包括加密货币交易，而无需中央授权。特别是，智能合约允许在区块链上执行任意代码，区块链本质上是一个大规模复制的最终一致的状态机。就联合学习而言，使用该技术可以通过使用智能合约进行模型聚合来实现全球服务器的分散，其中执行智能合约的参与客户可以是不同的公司或云服务。
然而，在如今的区块链平台上，如以太坊[409]，区块链上的数据默认是公开的，这可能会阻止用户参与分散式联合学习协议，因为数据的保护通常是FL的主要激励因素。为了解决这些问题，有可能修改现有的隐私保护技术，以适应分散式联合学习的场景。首先，为了防止参与节点利用单独提交的模型更新，可以使用现有的安全聚合协议。Bonawitz等人提出了一个实用的安全聚合协议，该协议已经在交叉设备FL中使用。[73]，以协议的复杂性为代价，有效地处理退学的参与者。另一种方法是让每个客户在区块链上持有加密货币的存款，如果在执行过程中退出，就会受到惩罚。在不需要处理退出的情况下，安全聚合协议可以显著简化。实现安全聚合的另一种方法是使用身份智能合约，如运行在安全区域内的Oasis协议[104]所支持的内容。这样，每个客户机可以简单地提交一个加密的本地模型更新，知道模型将通过远程证明在安全硬件中被解密和聚合（尽管参见第4.1节中对隐私的深入讨论）。
为了防止任何客户端试图利用全局模型重建另一个客户端的私有数据，客户端级别的差异隐私[290]已经被提出用于FL。客户端级别的差异隐私是通过在聚合的全局模型上添加足以隐藏任何单个客户端更新的随机高斯噪声来实现的。在分散联邦学习的情况下，我们也可以让每个客户端在本地添加噪声，如[54]中所做的那样。也就是说，每个客户端在经过局部梯度下降步骤后，局部加入一定量的高斯噪声，并将模型提交给区块链。计算本地增加的噪音等级，使得区块链上的聚集噪音能够实现与[290]中相同的客户端级别的差异隐私。最后，区块链上聚合的全局模型可以被加密，只有参与的客户端持有解密密钥，从而保护模型不被公开。
2.2跨库联合学习
与跨设备联合学习的特点（见表1）相比，跨思洛联邦学习允许在总体设计的某些方面具有更大的灵活性，但同时也提供了一种实现其他属性可能更困难的设置。本节讨论了其中的一些差异。
当许多公司或组织分享基于其所有数据培训模型的激励，但不能直接共享其数据时，交叉筒仓设置可能是相关的。由于地理限制，他们无法在同一个公司区域内集中数据，或者由于地理限制而无法集中。这些跨筒仓的应用引起了广泛的关注。
在跨设备设置中的数据分区假定通过示例对数据进行分区。在跨数据竖井中，除了通过示例进行分区外，按特征进行分区具有实际意义。例如，不同业务的两家公司拥有相同或重叠的客户集，例如同一城市的本地银行和本地零售公司。这种差异也被Yang等人称为横向和纵向联合学习。[419]。
具有按功能分区数据的跨思洛FL，与按示例划分数据的设置相比，采用了截然不同的培训体系结构。它可能涉及也可能不涉及作为中立方的中央服务器，并且根据训练算法的具体情况，客户交换特定的中间结果而不是模型参数，以帮助其他方计算梯度；例如，参见[419，第2.4.2节]。在此背景下，提出了安全多方计算或同态加密等技术的应用，以限制其他参与者通过观察训练过程可以推断出的信息量。这种方法的缺点是训练算法通常依赖于所追求的机器学习目标的类型。目前提出的算法包括树[103]、线性和逻辑回归[419198]和神经网络[276]。
联邦传输学习[419]是另一个概念，它考虑了数据方在用户空间或特征空间中只共享部分重叠的具有挑战性的场景，并利用现有的传输学习技术[314]协作构建模型。现有的公式仅限于2个客户的情况。
当单个公司由于法律限制而无法集中其数据时，或者当具有类似目标的组织希望协作改进其模型时，按示例划分通常与跨思洛FL相关。例如，不同的银行可以协作训练欺诈检测的分类或异常检测模型[407]，医院可以建立更好的诊断模型[121]，等等。
一个支持上述应用程序的开源平台目前可用作Federated AI Technology Enabler（FATE）[34]。同时，ieeep3652.1联邦机器学习工作组正在关注联邦AI技术框架的标准设置。
激励机制除了开发新的FL算法技术外，诚信参与的激励机制设计是一个重要的实践研究课题。这种需求可能出现在跨设备设置中（例如[225，224]），但在交叉竖井设置中尤其相关，因为参与者也可能是商业竞争对手。相关目标包括如何在贡献数据所有者之间分配联邦学习模型产生的收益，以维持长期参与，以及如何将激励措施与防御敌对数据所有者的决策联系起来，以增强系统安全性，优化数据所有者的参与，以提高系统效率。
差异隐私第4.1节中对参与者和威胁模型的讨论在很大程度上也与跨筒仓FL相关。但是，针对不同参与者的保护可能具有不同的优先级。例如，在许多实际情况下，最终培训的模型只会发布给参加培训的人员，这使得对“世界其他地区”的关注变得不那么重要。
另一方面，对于一个具有实际说服力的主张，我们通常需要一个本地差异隐私的概念，因为来自其他客户的潜在威胁可能更为重要。在客户不被视为重大威胁的情况下，每个客户都可以控制来自其各自用户的数据，并且在这种用户级别上可能需要正式的隐私保证。根据应用情况，其他目标可能值得追求。这一领域尚未得到系统的探索。
张量分解一些研究工作也研究了跨竖井联合张量分解，其中多个站点（每个站点都有一组具有相同特征的数据，i、 e.水平分区）通过只与协调服务器共享中间因子，同时保持每个站点的数据私有化，联合执行张量因子分解。在现有的研究中，[236]使用了基于交替方向乘法器（ADMM）的方法，[280]提高了弹性平均SGD（EASGD）算法的效率，并进一步确保了中间因素的差异隐私。
2.3拆分学习
与之前关注数据分区和通信模式的设置不同，split learning[190，393]3的关键思想是在客户机和服务器之间按层划分模型的执行。这可以用于训练和推理。
在分离学习的最简单配置中，每个客户端计算通过一个深层网络的前向传递，直到被称为剪切层的特定层。剪切层的输出（称为粉碎数据）被发送到另一个实体（服务器或另一个客户机），完成其余的计算。这样就完成了一轮前向传播，而不共享原始数据。然后，渐变可以以类似的方式从最后一层反向传播到剪切层。剪切层上的渐变（而且只有这些渐变）被发送回客户端，在那里完成其余的反向传播。这个过程一直持续到融合，而不让客户机直接访问彼此的原始数据。这个设置如图2（a）所示，图2（b）显示了这个设置的变体，其中标签也不与原始数据一起共享。
图2:Split learning配置显示在普通设置中未传输原始数据，在U形拆分学习设置中，原始数据和标签不会在客户端和服务器实体之间传输。
在几种情况下，分离学习和联合学习的总体通信需求在[360]中进行了比较。分割学习在培训中引入了并行性的另一个维度，即模型的各个部分（如客户机和服务器）之间的并行化。文献[2132007]中的思想，作者通过将不同部分的计算并行化，打破了部分网络之间的依赖关系，减少了集中训练的总时间，这一点也与此相关。然而，在边缘设备上探索这种分裂学习的并行化仍然是一个悬而未决的问题。分割学习还支持将客户端模型组件与最佳服务器端模型组件进行匹配，以实现模型选择的自动化，如ExpertMatcher[353]所示。
然而，一般来说，传递的值可以揭示有关基础数据的信息。多少以及这是否可以接受，可能取决于应用和配置规范。称为NoPeek SplitNN[395]的拆分学习变体通过减少与原始数据的距离相关性[394378]，减少了通过交流活动产生的潜在泄漏，同时通过分类交叉熵保持良好的模型性能。其核心思想是最小化原始数据点与通信的破碎数据之间的距离相关性。如果不使用NoPeek SplitNN，则通信的对象可能包含与输入数据高度相关的信息，而NoPeek SplitNN的使用也使得在给定解相关的情况下，可以相对较早地进行分割。第4节中的大部分讨论也与此相关，而且专门为分割学习提供正式隐私保证的分析仍然是一个开放的问题。
3提高效率和效果
在本节中，我们将探讨各种技术和开放性问题，以解决如何使联合学习更有效和有效的挑战。这包括大量可能的方法，包括：开发更好的优化算法；为不同的客户提供不同的模型；在FL上下文中使诸如超参数搜索、架构搜索和调试等ML任务变得更容易；提高通信效率；等等。
实现这些目标的一个基本挑战是非IID数据的存在，因此我们首先调查这个问题并强调潜在的缓解措施。
3.1联合学习中的非IID数据
虽然IID的含义通常很清楚，但数据在许多方面可能是非IID的。在本节中，我们将提供可能出现在任何客户端分区数据集中的非IID数据体制的分类法。最常见的依赖性和不一致性源于每个客户端对应于特定用户、特定地理位置和/或特定时间窗口。这种分类法与dataset shift[304，327]的概念有着密切的对应关系，它研究训练分布和测试分布之间的差异；这里，我们考虑每个客户机上数据分布的差异。
对于以下内容，请考虑一个具有特征x和标签y的监督任务。联邦学习的统计模型包括两个级别的采样：访问数据点需要首先对客户i∼Q进行抽样，然后从该客户的i∼P（x；y）中抽取一个示例（x；y）∼P（x；y）i本地数据分发。
